# Dumb Language Identification System (ML/Python)

## ğŸ“ Project Overview
Developed a real-time sign language recognition system using machine learning and computer vision. The system translates hand gestures into text or speech, assisting individuals with hearing and speech impairments in effective communication.

## ğŸ”¹ Features
- **Real-Time Gesture Recognition**: Uses OpenCV and TensorFlow to detect and classify hand gestures.
- **Machine Learning Model**: Trained a neural network using TensorFlow for accurate sign language identification.
- **Dataset Handling**: Collected and preprocessed a dataset of sign language gestures for training and validation.
- **Live Prediction**: Captures video input and provides real-time predictions, displaying recognized words on screen.
- **Text-to-Speech Integration**: Converts recognized signs into spoken words for seamless communication.
- **User-Friendly Interface**: Designed an intuitive interface to display recognized gestures clearly.

## ğŸ“Œ Technologies Used
- **Programming Language**: Python
- **Libraries**: TensorFlow, OpenCV, NumPy, Pandas
- **Concepts**: Deep Learning, Image Processing, Computer Vision

## ğŸ“· Screenshots (Add images here if available)

## ğŸ“‚ How to Run
1. Clone the repository.
2. Install dependencies using `pip install tensorflow opencv-python numpy pandas`.
3. Run `train_model.py` to train the model on the dataset.
4. Execute `recognition.py` to start real-time sign detection.

## ğŸš€ Future Improvements
- Expand the dataset to include more gestures and regional sign languages.
- Improve model accuracy using advanced deep learning techniques.
- Develop a mobile application for accessibility on smartphones.

## ğŸ“« Contact
For any queries or contributions, reach out via:
- **Email**: [vidurakavindadev@gmail.com](mailto:vidurakavindadev@gmail.com)
- **LinkedIn**: [Vidura Kavinda](https://www.linkedin.com/in/vidura-kavinda-a76b34204/)
